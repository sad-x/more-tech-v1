# MoreTech SCD2 Loader

## Проблематика

В озере данных ВТБ необходимо хранить полную историю изменений из оперативного хранилища данных, поступающую в формате SCD2.
При обработке новых сущностей записи добавляются в реплику. Но при обновлении существующих сущностей требуется изменить дату окончания действия у предыдущей записи по идентификатору сущности.
Выбранная архитектура озера данных не поддерживает операции обновления. Возникает проблема эффективной обработки инкрементальных данных и корректного обновления реплики в приемлемые для пользователей сроки.

## Решение v1 (директория - src)

- Движок для обработки данных: Apache Spark.
- Формат хранения данных: Apache Parquet.

Алгоритм:
1. Добавление полей партицирования eff_from_month и eff_to_month: последние дни месяца даты начала и окончания действия записи. 
2. Партицирование инкремента по добавленным полям.
3. Запись инкремента во временную таблицу.
4. Подготовка вспомогательного датафрейма из ключевых полей (id, eff_from_dt) уникальных закрытых записей инкремента
5. Поиск открытых записей в реплике, которые не требуют обновления, с последующим добавлением их во временную таблицу. Реализовано через anti join реплики и вспомогательного датафрейма из предыдущего пункта. Обработка происходит в цикле для каждой субпартиции eff_from_month в реплике для партиции с открытыми записями, где eff_to_month=5999-12-31. Данный этап выполняется в несколько потоков для улучшения производительности.
6. Удаление открытых записей из реплики 
7. Запись всей временной таблицы в реплику

Особенности решения:
- Реализовано логирование каждого запуска с замерами скорости по каждому этапу для более удобного отслеживания хода работы и производительности
- Конфигурация модуля выполняется посредством .ini файла
- Для большей гибкости решения предоставляется возможность запуска с разным количеством параллельно работающих потоков. Наилучшего результата на **среднем** датасете (level=3) на ресурсах тестового стенда удалось добиться при запуске конфигурации с 4 потоками


## Решение v2 (директория - iceberg)

- Движок для обработки данных: Apache Spark.
- Формат хранения данных: Apache Iceberg.

Алгоритм:
1. Запись инкремента из формата Parquet в формат Iceberg (Данный шаг необходим, так как инкремент приходит в формате Parquet)
2. MERGE INTO в реплику из инкремента с условием обновления по id и eff_from_dt

Особенности решения:
- Реализовано логирование каждого запуска с замерами скорости по каждому этапу для более удобного отслеживания хода работы и производительности
- Конфигурация модуля выполняется посредством .ini файла и аргументов командной строки
- Для Apache Iceberg выбран JDBC каталог (PostgreSQL)
- Реплика партицируется выражением months(eff_to_dt)


## Запуск

**Пререквизиты**
**v1:**
1. Создать поддиректорию /logs в директорию в директории, где находятся исходные скрипты. В данной директории будет вестись журналирование процессов.
2. Заменить во всех файлах плейсхолдеры* имен и ключей бакета S3 (<BUCKET_NAME>, <ACCESS_KEY>, <SECRET_KEY>) на реальные значения.
3. Запускать скрипты в порядке, указанном далее и с одинаковыми значениями параметра level. 
**v2:**
1. Выполнить пункты 1-3 для v1
2. Поднять и настроить инстанс postgresql
3. Настроить аутентификацию для пользователя в postgresql
4. Добавить данные для подключения пользователя в конфигурационный .ini файл

level - вариант тестируемых данных:
- 2 - маленький набор данных (10млн-1млн)
- 3 - средний набор данных (100млн-10млн)
- 4 - большой набор данных (1млрд-100млн)

*Адрес и ключи S3-бакета заменены заглушками вида <ПАРАМЕТР> как в самих скриптах, так и в конфигурационном .ini файле в целях безопасности. 
Пожалуйста убедитесь, что перед запуском заглушки были заменены на реальные данные для авторизации.


**Порядок запуска**
*Для запуска второй версии требуется также добавить при запуске ключи:
```commandline
--driver-class-path /opt/spark/jars/postgresql-42.7.3.jar --packages org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.1
```


1. Инициализация данных

```commandline
/opt/spark/bin/spark-submit --jars ~/spark-hadoop-cloud_2.13-3.5.3.jar src/copy_init.py -l <level>
```

2. Запуск применения инкремента

```commandline
/opt/spark/bin/spark-submit --jars ~/spark-hadoop-cloud_2.13-3.5.3.jar src/join.py -l <level>
```

3. Проверка тестируемых данных

```commandline
/opt/spark/bin/spark-submit --jars ~/spark-hadoop-cloud_2.13-3.5.3.jar src/check_result.py -l <level>
```